{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36a7a1a3",
   "metadata": {},
   "source": [
    "\n",
    "# House Price Prediction with External Features (End-to-End)\n",
    "**Goal:** Predict house prices using a base housing dataset and enrich it with external (scraped) neighborhood features — end-to-end ML workflow.\n",
    "\n",
    "**Workflow:**\n",
    "1. Problem Definition\n",
    "2. Data Collection (sklearn California housing dataset as base + HTML scraping example for extra features)\n",
    "3. Data Understanding (EDA)\n",
    "4. Data Preprocessing (missing values, outliers, encoding, scaling)\n",
    "5. Feature Engineering\n",
    "6. Splitting Data (70/15/15)\n",
    "7. Model Training (Linear Regression, Random Forest, XGBoost if available)\n",
    "8. Model Evaluation (RMSE, MAE, R²) + cross-validation\n",
    "9. Hyperparameter Tuning (RandomizedSearchCV)\n",
    "10. Monitoring / Logging demo\n",
    "11. Save Best Model\n",
    "\n",
    "> **Note:** The classic Boston dataset is deprecated/removed in `scikit-learn`. We use **California Housing** as the base. External features are scraped from a local HTML table to keep things self-contained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cb11df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings, logging, math, os, sys\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Try XGBoost\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    XGB_AVAILABLE = True\n",
    "except Exception as e:\n",
    "    XGB_AVAILABLE = False\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(\"house_price_project\")\n",
    "logger.info(\"Logger initialized.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a83226f",
   "metadata": {},
   "source": [
    "\n",
    "## 1–2) Problem Definition & Data Collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabdfd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Base dataset: California housing\n",
    "cal = fetch_california_housing(as_frame=True)\n",
    "df = cal.frame.rename(columns={\n",
    "    \"MedInc\": \"median_income\",\n",
    "    \"HouseAge\": \"house_age\",\n",
    "    \"AveRooms\": \"avg_rooms\",\n",
    "    \"AveBedrms\": \"avg_bedrooms\",\n",
    "    \"Population\": \"population\",\n",
    "    \"AveOccup\": \"avg_occupancy\",\n",
    "    \"Latitude\": \"latitude\",\n",
    "    \"Longitude\": \"longitude\",\n",
    "    \"MedHouseVal\": \"median_house_value\"\n",
    "})\n",
    "logger.info(f\"Base dataset shape: {df.shape}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f57b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assign synthetic cities by lat/long\n",
    "def assign_city(lat, lon):\n",
    "    if lat > 36 and lon < -119:\n",
    "        return \"Northwest City\"\n",
    "    elif lat > 36 and lon >= -119:\n",
    "        return \"Northeast City\"\n",
    "    elif lat <= 36 and lon < -119:\n",
    "        return \"Southwest City\"\n",
    "    else:\n",
    "        return \"Southeast City\"\n",
    "\n",
    "df[\"city\"] = [assign_city(lat, lon) for lat, lon in zip(df[\"latitude\"], df[\"longitude\"])]\n",
    "df[\"city\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b144ad6",
   "metadata": {},
   "source": [
    "\n",
    "### Create a local HTML file to simulate scraping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6936ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate a small HTML file with \"scraped\" features\n",
    "html_content = \"\"\"\n",
    "<html>\n",
    "  <body>\n",
    "    <table class=\"table_indices\">\n",
    "      <tr><th>City</th><th>CrimeIndex</th><th>SchoolRating</th><th>IncomeScore</th></tr>\n",
    "      <tr><td>Northwest City</td><td>42.1</td><td>7.8</td><td>68</td></tr>\n",
    "      <tr><td>Northeast City</td><td>35.5</td><td>8.2</td><td>74</td></tr>\n",
    "      <tr><td>Southwest City</td><td>58.0</td><td>6.5</td><td>60</td></tr>\n",
    "      <tr><td>Southeast City</td><td>50.3</td><td>7.0</td><td>63</td></tr>\n",
    "    </table>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "os.makedirs(\"data_external\", exist_ok=True)\n",
    "with open(\"data_external/neighborhood_stats.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html_content)\n",
    "\"data_external/neighborhood_stats.html\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ed8836",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scrape the local HTML\n",
    "from bs4 import BeautifulSoup\n",
    "with open(\"data_external/neighborhood_stats.html\", \"r\", encoding=\"utf-8\") as f:\n",
    "    soup = BeautifulSoup(f.read(), \"html.parser\")\n",
    "\n",
    "table = soup.find(\"table\", {\"class\": \"table_indices\"})\n",
    "rows = table.find_all(\"tr\")\n",
    "\n",
    "scraped_records = []\n",
    "for row in rows[1:]:\n",
    "    cols = [c.text.strip() for c in row.find_all([\"td\", \"th\"])]\n",
    "    if len(cols) == 4:\n",
    "        scraped_records.append({\n",
    "            \"city\": cols[0],\n",
    "            \"crime_index\": float(cols[1]),\n",
    "            \"school_rating\": float(cols[2]),\n",
    "            \"income_score\": float(cols[3])\n",
    "        })\n",
    "\n",
    "df_scraped = pd.DataFrame(scraped_records)\n",
    "df_scraped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f83f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Merge scraped features\n",
    "df_merged = df.merge(df_scraped, on=\"city\", how=\"left\")\n",
    "logger.info(f\"Merged shape: {df_merged.shape}\")\n",
    "df_merged.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d4bd2a",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Data Understanding (EDA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe433ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_merged.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d5f585",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_merged.describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce3cf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_merged.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b788f8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "df_merged[\"median_house_value\"].hist()\n",
    "plt.title(\"Target Distribution: median_house_value\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2884c2ef",
   "metadata": {},
   "source": [
    "\n",
    "## 4–5) Preprocessing & Feature Engineering\n",
    "- Clip outliers (1st–99th quantiles)\n",
    "- One-hot city\n",
    "- Scale numerics\n",
    "- Engineered features:\n",
    "  - rooms_per_occupant = avg_rooms / (avg_occupancy + 1e-3)\n",
    "  - crime_x_income = crime_index * median_income\n",
    "  - school_x_income = school_rating * median_income\n",
    "  - pop_per_room = population / (avg_rooms + 1e-3)\n",
    "  - coastal_proximity = max(0, -118.5 - longitude)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e16bbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ClipOutliers(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, qlow=0.01, qhigh=0.99):\n",
    "        self.qlow = qlow\n",
    "        self.qhigh = qhigh\n",
    "        self.lower_ = None\n",
    "        self.upper_ = None\n",
    "        self.columns_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = pd.DataFrame(X).copy()\n",
    "        self.columns_ = X.columns\n",
    "        self.lower_ = X.quantile(self.qlow)\n",
    "        self.upper_ = X.quantile(self.qhigh)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.DataFrame(X).copy()\n",
    "        X = X.clip(lower=self.lower_, upper=self.upper_, axis=1)\n",
    "        X.columns = self.columns_\n",
    "        return X\n",
    "\n",
    "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[\"rooms_per_occupant\"] = X[\"avg_rooms\"] / (X[\"avg_occupancy\"] + 1e-3)\n",
    "        X[\"crime_x_income\"] = X[\"crime_index\"] * X[\"median_income\"]\n",
    "        X[\"school_x_income\"] = X[\"school_rating\"] * X[\"median_income\"]\n",
    "        X[\"pop_per_room\"] = X[\"population\"] / (X[\"avg_rooms\"] + 1e-3)\n",
    "        X[\"coastal_proximity\"] = np.maximum(0.0, -118.5 - X[\"longitude\"])\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa83daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_col = \"median_house_value\"\n",
    "categorical_cols = [\"city\"]\n",
    "numeric_cols = [c for c in df_merged.columns if c not in categorical_cols + [target_col]]\n",
    "\n",
    "X = df_merged.drop(columns=[target_col])\n",
    "y = df_merged[target_col]\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42)\n",
    "\n",
    "numeric_processor = Pipeline(steps=[\n",
    "    (\"clip\", ClipOutliers(0.01, 0.99)),\n",
    "    (\"fe\", FeatureEngineer()),\n",
    "    (\"scale\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_processor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_processor, numeric_cols),\n",
    "        (\"cat\", categorical_processor, categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "def evaluate(model, X_tr, y_tr, X_v, y_v, name=\"Model\"):\n",
    "    pred_tr = model.predict(X_tr)\n",
    "    pred_v = model.predict(X_v)\n",
    "    rmse_tr = np.sqrt(mean_squared_error(y_tr, pred_tr))\n",
    "    rmse_v = np.sqrt(mean_squared_error(y_v, pred_v))\n",
    "    mae_v = mean_absolute_error(y_v, pred_v)\n",
    "    r2_v = r2_score(y_v, pred_v)\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  RMSE (train): {rmse_tr:.3f}\")\n",
    "    print(f\"  RMSE (val)  : {rmse_v:.3f}\")\n",
    "    print(f\"  MAE  (val)  : {mae_v:.3f}\")\n",
    "    print(f\"  R^2  (val)  : {r2_v:.4f}\")\n",
    "    return {\"rmse_tr\": rmse_tr, \"rmse_val\": rmse_v, \"mae_val\": mae_v, \"r2_val\": r2_v}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4b82ee",
   "metadata": {},
   "source": [
    "\n",
    "## 6–8) Modeling & Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ae9bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Linear Regression\n",
    "linreg = Pipeline(steps=[(\"prep\", preprocessor), (\"model\", LinearRegression())])\n",
    "linreg.fit(X_train, y_train)\n",
    "metrics_lin = evaluate(linreg, X_train, y_train, X_val, y_val, \"LinearRegression\")\n",
    "\n",
    "# Random Forest\n",
    "rf = Pipeline(steps=[(\"prep\", preprocessor), (\"model\", RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1))])\n",
    "rf.fit(X_train, y_train)\n",
    "metrics_rf = evaluate(rf, X_train, y_train, X_val, y_val, \"RandomForestRegressor\")\n",
    "\n",
    "# XGBoost (if available)\n",
    "if XGB_AVAILABLE:\n",
    "    xgb = Pipeline(steps=[(\"prep\", preprocessor), (\"model\", XGBRegressor(n_estimators=400, max_depth=6, subsample=0.8,\n",
    "                                                                        colsample_bytree=0.8, learning_rate=0.05,\n",
    "                                                                        reg_lambda=1.0, random_state=42, n_jobs=-1,\n",
    "                                                                        tree_method=\"hist\"))])\n",
    "    xgb.fit(X_train, y_train)\n",
    "    metrics_xgb = evaluate(xgb, X_train, y_train, X_val, y_val, \"XGBRegressor\")\n",
    "else:\n",
    "    print(\"XGBoost not installed; skipping.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949ab86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cross-validation with RF on training fold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(rf, X_train, y_train, cv=kf, scoring=\"neg_root_mean_squared_error\", n_jobs=-1)\n",
    "print(\"RandomForest 5-fold CV RMSE:\", -cv_scores)\n",
    "print(\"Mean CV RMSE:\", np.mean(-cv_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e65abc",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Hyperparameter Tuning (RandomizedSearchCV on RF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a791164",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_dist = {\n",
    "    \"model__n_estimators\": [200, 300, 400, 600, 800],\n",
    "    \"model__max_depth\": [None, 10, 15, 20, 30],\n",
    "    \"model__min_samples_split\": [2, 5, 10],\n",
    "    \"model__min_samples_leaf\": [1, 2, 4],\n",
    "    \"model__max_features\": [\"sqrt\", \"log2\", None]\n",
    "}\n",
    "\n",
    "rf_tune = Pipeline(steps=[(\"prep\", preprocessor), (\"model\", RandomForestRegressor(random_state=42, n_jobs=-1))])\n",
    "\n",
    "rs = RandomizedSearchCV(\n",
    "    rf_tune,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=15,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rs.fit(X_train, y_train)\n",
    "print(\"Best params:\", rs.best_params_)\n",
    "print(\"Best CV score (neg RMSE):\", rs.best_score_)\n",
    "\n",
    "best_rf = rs.best_estimator_\n",
    "_ = evaluate(best_rf, X_train, y_train, X_val, y_val, \"Best RandomForest (Tuned)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba70bea",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Final Test Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca46fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_rmses = [(\"LinearRegression\", metrics_lin[\"rmse_val\"]), (\"RandomForest\", metrics_rf[\"rmse_val\"])]\n",
    "models = {\"LinearRegression\": linreg, \"RandomForest\": rf}\n",
    "\n",
    "if 'best_rf' in globals():\n",
    "    pred_v_best = best_rf.predict(X_val)\n",
    "    rmse_v_best = np.sqrt(mean_squared_error(y_val, pred_v_best))\n",
    "    val_rmses.append((\"BestRandomForest\", rmse_v_best))\n",
    "    models[\"BestRandomForest\"] = best_rf\n",
    "\n",
    "if XGB_AVAILABLE:\n",
    "    val_rmses.append((\"XGBRegressor\", metrics_xgb[\"rmse_val\"]))\n",
    "    models[\"XGBRegressor\"] = xgb\n",
    "\n",
    "best_name, _ = sorted(val_rmses, key=lambda t: t[1])[0]\n",
    "best_model = models[best_name]\n",
    "print(\"Selected best model:\", best_name)\n",
    "\n",
    "pred_test = best_model.predict(X_test)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, pred_test))\n",
    "mae_test = mean_absolute_error(y_test, pred_test)\n",
    "r2_test = r2_score(y_test, pred_test)\n",
    "\n",
    "print(f\"Test RMSE: {rmse_test:.3f}\")\n",
    "print(f\"Test MAE : {mae_test:.3f}\")\n",
    "print(f\"Test R^2 : {r2_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60d9c58",
   "metadata": {},
   "source": [
    "\n",
    "## 10) Monitoring / Logging Demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a1f331",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def log_prediction(example_features: dict, model, label=\"prediction\"):\n",
    "    x_df = pd.DataFrame([example_features])\n",
    "    y_pred = model.predict(x_df)[0]\n",
    "    logger.info(f\"{label} -> input: {example_features} | predicted_price: {y_pred:.3f}\")\n",
    "    return y_pred\n",
    "\n",
    "mean_row = X_train.mean(numeric_only=True).to_dict()\n",
    "mean_row.update({\"city\": \"Northwest City\"})\n",
    "_ = log_prediction(mean_row, best_model, label=\"demo_prediction\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5cd24c",
   "metadata": {},
   "source": [
    "\n",
    "## 11) Save Best Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc544c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs(\"artifacts\", exist_ok=True)\n",
    "model_path = \"artifacts/best_model.joblib\"\n",
    "joblib.dump(best_model, model_path)\n",
    "model_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213f08fc",
   "metadata": {},
   "source": [
    "\n",
    "## Inference Helper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1264f5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_model(path=\"artifacts/best_model.joblib\"):\n",
    "    return joblib.load(path)\n",
    "\n",
    "def predict_price(model, features: dict):\n",
    "    df_in = pd.DataFrame([features])\n",
    "    return float(model.predict(df_in)[0])\n",
    "\n",
    "mdl = load_model()\n",
    "example = {\n",
    "    \"median_income\": 3.0,\n",
    "    \"house_age\": 25.0,\n",
    "    \"avg_rooms\": 5.2,\n",
    "    \"avg_bedrooms\": 1.0,\n",
    "    \"population\": 750.0,\n",
    "    \"avg_occupancy\": 3.0,\n",
    "    \"latitude\": 35.0,\n",
    "    \"longitude\": -120.0,\n",
    "    \"city\": \"Southwest City\",\n",
    "    \"crime_index\": 58.0,\n",
    "    \"school_rating\": 6.5,\n",
    "    \"income_score\": 60.0\n",
    "}\n",
    "print(\"Predicted price:\", predict_price(mdl, example))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7664b4f2",
   "metadata": {},
   "source": [
    "\n",
    "## Appendix: Real Web Scraping Template\n",
    "\n",
    "```python\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.example.com/city-stats\"  # replace with a real source\n",
    "resp = requests.get(url, timeout=20)\n",
    "soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "table = soup.find(\"table\", {\"class\": \"table_indices\"})\n",
    "rows = table.find_all(\"tr\")\n",
    "\n",
    "scraped_records = []\n",
    "for row in rows[1:]:\n",
    "    cols = [c.text.strip() for c in row.find_all([\"td\", \"th\"])]\n",
    "    scraped_records.append({\n",
    "        \"city\": cols[0],\n",
    "        \"crime_index\": float(cols[1]),\n",
    "        \"school_rating\": float(cols[2]),\n",
    "        \"income_score\": float(cols[3])\n",
    "    })\n",
    "\n",
    "df_scraped = pd.DataFrame(scraped_records)\n",
    "```\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
